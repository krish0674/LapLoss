## Abstract

Contrast enhancement is a crucial component of image-to-image translation (I2IT) that improves visual quality by adjusting the intensity differences between pixels. However, many existing methods struggle to preserve fine-grained details, often leading to the loss of low-level features. This work proposes integrating adversarial training into a Laplacian pyramid to enhance contrast by introducing a multi-level discriminator architecture. In this approach, adversarial supervision is applied independently at each level of the Laplacian pyramid. By aligning discriminators with individual pyramid levels, the network learns scale-specific representationsâ€”capturing subtle edge details at higher frequencies while maintaining consistent brightness and structure at lower frequencies. This decomposition-driven supervision provides more localized and frequency-aware gradients during training, resulting in stable convergence and improved generalization across various lighting conditions. The ability to evaluate and optimize different frequency bands independently allows for targeted correction of distortions introduced at each scale, ultimately yielding more visually coherent and detail-preserving contrast enhancement. The proposed framework is validated on two distinct pyramidal architectures: the Laplacian Pyramid Transformer Network (LPTN) and the Laplacian Pyramid for Guided Thermal Super-Resolution (LapGSR). This highlights its flexibility and effectiveness across diverse multi-scale networks for contrast enhancement. The framework achieves state-of-the-art results, consistently performing well under different lighting conditions in the SICE dataset.

## Datasets

The work utilized publicly available standard datasets, namely SICEv1, SICEv2 available at https://github.com/csjcai/SICE and SICEMix, and SICEGrad available at https://drive.google.com/file/d/1gii4AEyyPp_kagfa7TyugnNPvUhkX84x/view.

Please note that the link provided is for reference purposes only. All ownership and rights to the dataset belong to the original authors. Any use of the dataset should comply with the terms and conditions set by the original authors.
